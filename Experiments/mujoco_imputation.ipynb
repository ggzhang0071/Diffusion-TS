{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imputation Experiment on MUJOCO Dataset\n",
    "\n",
    "Forked from [SSSD repo](https://github.com/AI4HealthUOL/SSSD) : \n",
    "\n",
    "We collected the dataset directly from [NRTSI repository](https://github.com/lupalab/NRTSI/tree/main/codes_regularly-sampled), which provides a [link](https://www.dropbox.com/s/pjccc2piis8g2fx/mujoco_train.npy?dl=0) for the train set, and another [link](https://www.dropbox.com/s/ktkswh77sueqfy8/mujoco_test.npy?dl=0) for the test set.  \n",
    "\n",
    "Shan, Siyuan, Yang Li, and Junier B. Oliva. \"Nrtsi: Non-recurrent time series imputation.\" arXiv preprint arXiv:2102.03340 (2021)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import sys\n",
    "sys.path.append(os.path.join(os.path.dirname('__file__'), '../'))\n",
    "\n",
    "from engine.solver import Trainer\n",
    "from torch.utils.data import Dataset\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from Utils.io_utils import load_yaml_config, instantiate_from_config\n",
    "from Models.interpretable_diffusion.model_utils import normalize_to_neg_one_to_one, unnormalize_to_zero_to_one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_mask(observed_values, missing_ratio=0.1, seed=1984, exclude_features=None):\n",
    "    observed_masks = ~np.isnan(observed_values)\n",
    "    if exclude_features is not None:\n",
    "        observed_masks[:, exclude_features] = False\n",
    "\n",
    "    # randomly set some percentage as ground-truth\n",
    "    masks = observed_masks.reshape(-1).copy()\n",
    "    obs_indices = np.where(masks)[0].tolist()\n",
    "\n",
    "    # Store the state of the RNG to restore later.\n",
    "    st0 = np.random.get_state()\n",
    "    np.random.seed(seed)\n",
    "\n",
    "    miss_indices = np.random.choice(\n",
    "        obs_indices, (int)(len(obs_indices) * missing_ratio), replace=False\n",
    "    )\n",
    "\n",
    "    # Restore RNG.\n",
    "    np.random.set_state(st0)\n",
    "    \n",
    "    masks[miss_indices] = False\n",
    "    gt_masks = masks.reshape(observed_masks.shape)\n",
    "    observed_values = np.nan_to_num(observed_values)\n",
    "    return observed_values, observed_masks, gt_masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MUJOCODataset(Dataset):\n",
    "    def __init__(self, data, regular=True, ratio=0.):\n",
    "        super(MUJOCODataset, self).__init__()\n",
    "        self.sample_num = data.shape[0]\n",
    "        self.samples = data\n",
    "        self.regular = regular\n",
    "        self.mask = np.empty([0, data.shape[1], data.shape[2]])\n",
    "        if not self.regular:\n",
    "            for i in range(data.shape[0]):\n",
    "                *_, mask = random_mask(data[i, :, :], ratio)\n",
    "                self.mask = np.row_stack([self.mask, np.expand_dims(mask, 0)])\n",
    "        self.mask = self.mask.astype(bool)\n",
    "\n",
    "    def __getitem__(self, ind):\n",
    "        x = self.samples[ind, :, :]\n",
    "        if self.regular:\n",
    "            return torch.from_numpy(x).float()\n",
    "        mask = self.mask[ind, :, :]\n",
    "        return torch.from_numpy(x).float(), torch.from_numpy(mask)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.sample_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8000, 100, 14) (2000, 100, 14)\n"
     ]
    }
   ],
   "source": [
    "train = np.load('../Data/mujoco_train.npy')  # downloaded from https://www.dropbox.com/s/pjccc2piis8g2fx/mujoco_train.npy?dl=0\n",
    "test = np.load('../Data/mujoco_test.npy')  # downloaded from https://www.dropbox.com/s/ktkswh77sueqfy8/mujoco_test.npy?dl=0\n",
    "\n",
    "print(train.shape, test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "train_scaled = normalize_to_neg_one_to_one(scaler.fit_transform(train.reshape(-1, train.shape[-1]))).reshape(train.shape)\n",
    "test_scaled = scaler.transform(test.reshape(-1, test.shape[-1])).reshape(test.shape)\n",
    "test_scaled = normalize_to_neg_one_to_one(test_scaled)\n",
    "\n",
    "train_dataset = MUJOCODataset(train_scaled)\n",
    "dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=64, shuffle=True, num_workers=0, pin_memory=True, sampler=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Args_Example:\n",
    "    def __init__(self) -> None:\n",
    "        self.config_path = '../Config/mujoco_sssd.yaml'\n",
    "        self.save_dir = '../imputation_exp'\n",
    "        self.gpu = 0\n",
    "        os.makedirs(self.save_dir, exist_ok=True)\n",
    "\n",
    "args =  Args_Example()\n",
    "configs = load_yaml_config(args.config_path)\n",
    "device = torch.device(f'cuda:{args.gpu}' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "model = instantiate_from_config(configs['model']).to(device)\n",
    "trainer = Trainer(config=configs, args=args, model=model, dataloader={'dataloader':dataloader})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 0.061392: 100%|███████████████████████████████████████████████| 12000/12000 [16:45<00:00, 11.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training complete\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "conditional sampling loop time step: 100%|██████████████████████████████| 200/200 [00:15<00:00, 13.08it/s]\n",
      "conditional sampling loop time step: 100%|██████████████████████████████| 200/200 [00:15<00:00, 12.83it/s]\n",
      "conditional sampling loop time step: 100%|██████████████████████████████| 200/200 [00:15<00:00, 13.26it/s]\n",
      "conditional sampling loop time step: 100%|██████████████████████████████| 200/200 [00:14<00:00, 13.47it/s]\n",
      "conditional sampling loop time step: 100%|██████████████████████████████| 200/200 [00:15<00:00, 12.89it/s]\n",
      "conditional sampling loop time step: 100%|██████████████████████████████| 200/200 [00:15<00:00, 13.00it/s]\n",
      "conditional sampling loop time step: 100%|██████████████████████████████| 200/200 [00:14<00:00, 13.49it/s]\n",
      "conditional sampling loop time step: 100%|██████████████████████████████| 200/200 [00:13<00:00, 14.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now with 0.7 unobserved: 0.0002681327173449267\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "conditional sampling loop time step: 100%|██████████████████████████████| 200/200 [00:14<00:00, 13.54it/s]\n",
      "conditional sampling loop time step: 100%|██████████████████████████████| 200/200 [00:15<00:00, 13.14it/s]\n",
      "conditional sampling loop time step: 100%|██████████████████████████████| 200/200 [00:16<00:00, 12.09it/s]\n",
      "conditional sampling loop time step: 100%|██████████████████████████████| 200/200 [00:14<00:00, 13.70it/s]\n",
      "conditional sampling loop time step: 100%|██████████████████████████████| 200/200 [00:15<00:00, 13.15it/s]\n",
      "conditional sampling loop time step: 100%|██████████████████████████████| 200/200 [00:15<00:00, 13.11it/s]\n",
      "conditional sampling loop time step: 100%|██████████████████████████████| 200/200 [00:15<00:00, 12.86it/s]\n",
      "conditional sampling loop time step: 100%|██████████████████████████████| 200/200 [00:14<00:00, 14.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now with 0.8 unobserved: 0.0003206820974546227\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "conditional sampling loop time step: 100%|██████████████████████████████| 200/200 [00:14<00:00, 13.48it/s]\n",
      "conditional sampling loop time step: 100%|██████████████████████████████| 200/200 [00:14<00:00, 13.41it/s]\n",
      "conditional sampling loop time step: 100%|██████████████████████████████| 200/200 [00:14<00:00, 13.34it/s]\n",
      "conditional sampling loop time step: 100%|██████████████████████████████| 200/200 [00:16<00:00, 12.49it/s]\n",
      "conditional sampling loop time step: 100%|██████████████████████████████| 200/200 [00:15<00:00, 13.09it/s]\n",
      "conditional sampling loop time step: 100%|██████████████████████████████| 200/200 [00:15<00:00, 12.72it/s]\n",
      "conditional sampling loop time step: 100%|██████████████████████████████| 200/200 [00:15<00:00, 12.64it/s]\n",
      "conditional sampling loop time step: 100%|██████████████████████████████| 200/200 [00:14<00:00, 14.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now with 0.9 unobserved: 0.0005479870025826176\n"
     ]
    }
   ],
   "source": [
    "sample_num, seq_length, feat_num = test_scaled.shape\n",
    "\n",
    "for missing_ratio in [0.7, 0.8, 0.9]:\n",
    "    mses = []\n",
    "    samples = np.empty([0, sample_num, seq_length, feat_num])\n",
    "    test_dataset = MUJOCODataset(test_scaled, regular=False, ratio=missing_ratio)\n",
    "    test_dataloader = torch.utils.data.DataLoader(test_dataset, batch_size=256, shuffle=False, num_workers=0, pin_memory=True, sampler=None)\n",
    "\n",
    "    sample, *_ = trainer.restore(test_dataloader, shape=[seq_length, feat_num], coef=1e-2, stepsize=5e-2, sampling_steps=200)\n",
    "    sample = scaler.inverse_transform(unnormalize_to_zero_to_one(sample.reshape(-1, feat_num))).reshape(sample.shape)\n",
    "    samples = np.row_stack([samples, np.expand_dims(sample, 0)])\n",
    "    mask = test_dataset.mask\n",
    "    mse = mean_squared_error(sample[~mask], test[~mask])\n",
    "    print(f'Now with {missing_ratio} unobserved: {mse}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
